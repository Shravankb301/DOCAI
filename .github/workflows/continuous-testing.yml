name: Continuous Testing and Automated Rebuilding

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'  # Run daily at midnight UTC

jobs:
  backend-tests:
    name: Backend Tests
    runs-on: ubuntu-latest
    
    services:
      # Add PostgreSQL service for database tests if needed
      postgres:
        image: postgres:14
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Install dependencies
        working-directory: ./backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio
      
      - name: Run linting
        working-directory: ./backend
        run: |
          pip install flake8
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
      
      - name: Run unit tests
        working-directory: ./backend
        run: |
          pytest tests/unit --cov=app --cov-report=xml
      
      - name: Run integration tests
        working-directory: ./backend
        run: |
          pytest tests/integration --cov=app --cov-append --cov-report=xml
      
      - name: Upload coverage report
        uses: codecov/codecov-action@v3
        with:
          file: ./backend/coverage.xml
          flags: backend
      
      - name: Check for test failures
        if: failure()
        run: |
          echo "Backend tests failed. Attempting to diagnose and fix issues..."
          # Add scripts to diagnose common issues
          python scripts/ci/diagnose_test_failures.py
      
      - name: Attempt automated fixes
        if: failure()
        run: |
          echo "Attempting automated fixes for common issues..."
          # Add scripts to fix common issues
          python scripts/ci/auto_fix_common_issues.py
      
      - name: Rerun failed tests
        if: failure()
        working-directory: ./backend
        run: |
          echo "Rerunning failed tests after attempted fixes..."
          pytest tests/unit tests/integration --last-failed --cov=app --cov-report=xml
  
  frontend-tests:
    name: Frontend Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: './frontend/package-lock.json'
      
      - name: Install dependencies
        working-directory: ./frontend
        run: npm ci
      
      - name: Run linting
        working-directory: ./frontend
        run: npm run lint
      
      - name: Run unit tests
        working-directory: ./frontend
        run: npm test -- --coverage
      
      - name: Upload coverage report
        uses: codecov/codecov-action@v3
        with:
          file: ./frontend/coverage/lcov.info
          flags: frontend
      
      - name: Check for test failures
        if: failure()
        run: |
          echo "Frontend tests failed. Attempting to diagnose and fix issues..."
          # Add scripts to diagnose common issues
          node scripts/ci/diagnose_frontend_failures.js
      
      - name: Attempt automated fixes
        if: failure()
        run: |
          echo "Attempting automated fixes for common issues..."
          # Add scripts to fix common issues
          node scripts/ci/auto_fix_frontend_issues.js
      
      - name: Rerun failed tests
        if: failure()
        working-directory: ./frontend
        run: npm test -- --findRelatedTests $(git diff --name-only)
  
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: './frontend/package-lock.json'
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Install backend dependencies
        working-directory: ./backend
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Install frontend dependencies
        working-directory: ./frontend
        run: npm ci
      
      - name: Install Playwright
        working-directory: ./frontend
        run: npx playwright install --with-deps
      
      - name: Start backend server
        working-directory: ./backend
        run: |
          python run.py &
          sleep 10  # Wait for backend to start
      
      - name: Start frontend server
        working-directory: ./frontend
        run: |
          npm run build
          npm run start &
          sleep 10  # Wait for frontend to start
      
      - name: Run E2E tests
        working-directory: ./frontend
        run: npx playwright test
      
      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: playwright-report
          path: ./frontend/playwright-report/
          retention-days: 30
      
      - name: Check for test failures
        if: failure()
        run: |
          echo "E2E tests failed. Attempting to diagnose and fix issues..."
          # Add scripts to diagnose common issues
          node scripts/ci/diagnose_e2e_failures.js
      
      - name: Attempt automated fixes
        if: failure()
        run: |
          echo "Attempting automated fixes for common issues..."
          # Add scripts to fix common issues
          node scripts/ci/auto_fix_e2e_issues.js
      
      - name: Rerun failed tests
        if: failure()
        working-directory: ./frontend
        run: npx playwright test --grep-invert @slow
  
  notify:
    name: Notify on Failure
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests, e2e-tests]
    if: failure()
    
    steps:
      - name: Send notification
        uses: rtCamp/action-slack-notify@v2
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
          SLACK_CHANNEL: ci-failures
          SLACK_COLOR: danger
          SLACK_TITLE: CI Pipeline Failed
          SLACK_MESSAGE: |
            CI pipeline failed. Please check the logs for more details.
            Workflow: ${{ github.workflow }}
            Run: ${{ github.run_id }}
            Commit: ${{ github.sha }}
            Repository: ${{ github.repository }}
            Branch: ${{ github.ref }}
          SLACK_FOOTER: "DocAI CI/CD Pipeline"
  
  rebuild-report:
    name: Generate Rebuild Report
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests, e2e-tests]
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Generate report
        run: |
          echo "# Test and Rebuild Report" > report.md
          echo "## Test Results" >> report.md
          echo "- Backend Tests: ${{ needs.backend-tests.result }}" >> report.md
          echo "- Frontend Tests: ${{ needs.frontend-tests.result }}" >> report.md
          echo "- E2E Tests: ${{ needs.e2e-tests.result }}" >> report.md
          echo "## Rebuild Actions" >> report.md
          echo "The following automated rebuild actions were taken:" >> report.md
          # Add more detailed reporting here
      
      - name: Upload report
        uses: actions/upload-artifact@v3
        with:
          name: rebuild-report
          path: report.md
          retention-days: 30
